{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pymatgen.core.structure import Structure\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pool(dataset_list):\n",
    "    \"\"\"\n",
    "    Collate a list of data and return a batch for predicting crystal\n",
    "    properties.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    dataset_list: list of tuples for each data point.\n",
    "      (atom_fea, nbr_fea, nbr_fea_idx, target)\n",
    "\n",
    "      atom_fea: torch.Tensor shape (n_i, atom_fea_len)\n",
    "      nbr_fea: torch.Tensor shape (n_i, M, nbr_fea_len)\n",
    "      nbr_fea_idx: torch.LongTensor shape (n_i, M)\n",
    "      target: torch.Tensor shape (1, )\n",
    "      cif_id: str or int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    N = sum(n_i); N0 = sum(i)\n",
    "\n",
    "    batch_atom_fea: torch.Tensor shape (N, orig_atom_fea_len)\n",
    "      Atom features from atom type\n",
    "    batch_nbr_fea: torch.Tensor shape (N, M, nbr_fea_len)\n",
    "      Bond features of each atom's M neighbors\n",
    "    batch_nbr_fea_idx: torch.LongTensor shape (N, M)\n",
    "      Indices of M neighbors of each atom\n",
    "    crystal_atom_idx: list of torch.LongTensor of length N0\n",
    "      Mapping from the crystal idx to atom idx\n",
    "    target: torch.Tensor shape (N, 1)\n",
    "      Target value for prediction\n",
    "    batch_cif_ids: list\n",
    "    \"\"\"\n",
    "    batch_atom_fea, batch_nbr_fea, batch_nbr_fea_idx = [], [], []\n",
    "    crystal_atom_idx, batch_target = [], []\n",
    "    batch_cif_ids = []\n",
    "    base_idx = 0\n",
    "    for i, ((atom_fea, nbr_fea, nbr_fea_idx), target, cif_id)\\\n",
    "            in enumerate(dataset_list):\n",
    "        n_i = atom_fea.shape[0]  # number of atoms for this crystal\n",
    "        batch_atom_fea.append(atom_fea)\n",
    "        batch_nbr_fea.append(nbr_fea)\n",
    "        batch_nbr_fea_idx.append(nbr_fea_idx+base_idx)\n",
    "        new_idx = torch.LongTensor(np.arange(n_i)+base_idx)\n",
    "        crystal_atom_idx.append(new_idx)\n",
    "        batch_target.append(target)\n",
    "        batch_cif_ids.append(cif_id)\n",
    "        base_idx += n_i\n",
    "    return (torch.cat(batch_atom_fea, dim=0),\n",
    "            torch.cat(batch_nbr_fea, dim=0),\n",
    "            torch.cat(batch_nbr_fea_idx, dim=0),\n",
    "            crystal_atom_idx),\\\n",
    "        torch.stack(batch_target, dim=0),\\\n",
    "        batch_cif_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDistance(object):\n",
    "    \"\"\"\n",
    "    Expands the distance by Gaussian basis.\n",
    "\n",
    "    Unit: angstrom\n",
    "    \"\"\"\n",
    "    def __init__(self, dmin, dmax, step, var=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        dmin: float\n",
    "          Minimum interatomic distance\n",
    "        dmax: float\n",
    "          Maximum interatomic distance\n",
    "        step: float\n",
    "          Step size for the Gaussian filter\n",
    "        \"\"\"\n",
    "        assert dmin < dmax\n",
    "        assert dmax - dmin > step\n",
    "        self.filter = np.arange(dmin, dmax+step, step)\n",
    "        if var is None:\n",
    "            var = step\n",
    "        self.var = var\n",
    "\n",
    "    def expand(self, distances):\n",
    "        \"\"\"\n",
    "        Apply Gaussian disntance filter to a numpy distance array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        distance: np.array shape n-d array\n",
    "          A distance matrix of any shape\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        expanded_distance: shape (n+1)-d array\n",
    "          Expanded distance matrix with the last dimension of length\n",
    "          len(self.filter)\n",
    "        \"\"\"\n",
    "        return np.exp(-(distances[..., np.newaxis] - self.filter)**2 /\n",
    "                      self.var**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomInitializer(object):\n",
    "    \"\"\"\n",
    "    Base class for intializing the vector representation for atoms.\n",
    "\n",
    "    !!! Use one AtomInitializer per dataset !!!\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_types):\n",
    "        self.atom_types = set(atom_types)\n",
    "        self._embedding = {}\n",
    "\n",
    "    def get_atom_fea(self, atom_type):\n",
    "        assert atom_type in self.atom_types\n",
    "        return self._embedding[atom_type]\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self._embedding = state_dict\n",
    "        self.atom_types = set(self._embedding.keys())\n",
    "        self._decodedict = {idx: atom_type for atom_type, idx in\n",
    "                            self._embedding.items()}\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self._embedding\n",
    "\n",
    "    def decode(self, idx):\n",
    "        if not hasattr(self, '_decodedict'):\n",
    "            self._decodedict = {idx: atom_type for atom_type, idx in\n",
    "                                self._embedding.items()}\n",
    "        return self._decodedict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomCustomJSONInitializer(AtomInitializer):\n",
    "    \"\"\"\n",
    "    Initialize atom feature vectors using a JSON file, which is a python\n",
    "    dictionary mapping from element number to a list representing the\n",
    "    feature vector of the element.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    elem_embedding_file: str\n",
    "        The path to the .json file\n",
    "    \"\"\"\n",
    "    def __init__(self, elem_embedding_file):\n",
    "        with open(elem_embedding_file) as f:\n",
    "            elem_embedding = json.load(f)\n",
    "        elem_embedding = {int(key): value for key, value\n",
    "                          in elem_embedding.items()}\n",
    "        atom_types = set(elem_embedding.keys())\n",
    "        super(AtomCustomJSONInitializer, self).__init__(atom_types)\n",
    "        for key, value in elem_embedding.items():\n",
    "            self._embedding[key] = np.array(value, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CIFData(Dataset):\n",
    "    \"\"\"\n",
    "    The CIFData dataset is a wrapper for a dataset where the crystal structures\n",
    "    are stored in the form of CIF files. The dataset should have the following\n",
    "    directory structure:\n",
    "\n",
    "    root_dir\n",
    "    ├── id_prop.csv\n",
    "    ├── atom_init.json\n",
    "    ├── id0.cif\n",
    "    ├── id1.cif\n",
    "    ├── ...\n",
    "\n",
    "    id_prop.csv: a CSV file with two columns. The first column recodes a\n",
    "    unique ID for each crystal, and the second column recodes the value of\n",
    "    target property.\n",
    "\n",
    "    atom_init.json: a JSON file that stores the initialization vector for each\n",
    "    element.\n",
    "\n",
    "    ID.cif: a CIF file that recodes the crystal structure, where ID is the\n",
    "    unique ID for the crystal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    root_dir: str\n",
    "        The path to the root directory of the dataset\n",
    "    max_num_nbr: int\n",
    "        The maximum number of neighbors while constructing the crystal graph\n",
    "    radius: float\n",
    "        The cutoff radius for searching neighbors\n",
    "    dmin: float\n",
    "        The minimum distance for constructing GaussianDistance\n",
    "    step: float\n",
    "        The step size for constructing GaussianDistance\n",
    "    random_seed: int\n",
    "        Random seed for shuffling the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    atom_fea: torch.Tensor shape (n_i, atom_fea_len)\n",
    "    nbr_fea: torch.Tensor shape (n_i, M, nbr_fea_len)\n",
    "    nbr_fea_idx: torch.LongTensor shape (n_i, M)\n",
    "    target: torch.Tensor shape (1, )\n",
    "    cif_id: str or int\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, max_num_nbr=12, radius=8, dmin=0, step=0.2,\n",
    "                 random_seed=123):\n",
    "        self.root_dir = root_dir\n",
    "        self.max_num_nbr, self.radius = max_num_nbr, radius\n",
    "        assert os.path.exists(root_dir), 'root_dir does not exist!'\n",
    "        id_prop_file = os.path.join(self.root_dir, 'id_prop.csv')\n",
    "        assert os.path.exists(id_prop_file), 'id_prop.csv does not exist!'\n",
    "        with open(id_prop_file) as f:\n",
    "            reader = csv.reader(f)\n",
    "            self.id_prop_data = [row for row in reader]\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(self.id_prop_data)\n",
    "        atom_init_file = os.path.join(self.root_dir, 'atom_init.json')\n",
    "        assert os.path.exists(atom_init_file), 'atom_init.json does not exist!'\n",
    "        self.ari = AtomCustomJSONInitializer(atom_init_file)\n",
    "        self.gdf = GaussianDistance(dmin=dmin, dmax=self.radius, step=step)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_prop_data)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)  # Cache loaded structures\n",
    "    def __getitem__(self, idx):\n",
    "        cif_id, target = self.id_prop_data[idx]\n",
    "        crystal = Structure.from_file(os.path.join(self.root_dir,\n",
    "                                                   cif_id+'.cif'))\n",
    "        atom_fea = np.vstack([self.ari.get_atom_fea(crystal[i].specie.number)\n",
    "                              for i in range(len(crystal))])\n",
    "        atom_fea = torch.Tensor(atom_fea)\n",
    "        all_nbrs = crystal.get_all_neighbors(self.radius, include_index=True)\n",
    "        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n",
    "        nbr_fea_idx, nbr_fea = [], []\n",
    "        for nbr in all_nbrs:\n",
    "            if len(nbr) < self.max_num_nbr:\n",
    "                warnings.warn('{} not find enough neighbors to build graph. '\n",
    "                              'If it happens frequently, consider increase '\n",
    "                              'radius.'.format(cif_id))\n",
    "                nbr_fea_idx.append(list(map(lambda x: x[2], nbr)) +\n",
    "                                   [0] * (self.max_num_nbr - len(nbr)))\n",
    "                nbr_fea.append(list(map(lambda x: x[1], nbr)) +\n",
    "                               [self.radius + 1.] * (self.max_num_nbr -\n",
    "                                                     len(nbr)))\n",
    "            else:\n",
    "                nbr_fea_idx.append(list(map(lambda x: x[2],\n",
    "                                            nbr[:self.max_num_nbr])))\n",
    "                nbr_fea.append(list(map(lambda x: x[1],\n",
    "                                        nbr[:self.max_num_nbr])))\n",
    "        nbr_fea_idx, nbr_fea = np.array(nbr_fea_idx), np.array(nbr_fea)\n",
    "        nbr_fea = self.gdf.expand(nbr_fea)\n",
    "\n",
    "        n_atoms, h = nbr_fea_idx.shape\n",
    "        r1 = np.array([[i,]*h for i in range(n_atoms)])\n",
    "        r2 = np.stack([r1, nbr_fea_idx], axis=0)\n",
    "        nbr_fea_idx = np.reshape(r2, (2, -1))\n",
    "        nbr_fea = np.reshape(nbr_fea, (-1, 41))\n",
    "\n",
    "        atom_fea = torch.Tensor(atom_fea)\n",
    "        nbr_fea = torch.Tensor(nbr_fea)\n",
    "        nbr_fea_idx = torch.LongTensor(nbr_fea_idx)\n",
    "        target = torch.Tensor([float(target)])\n",
    "        return (atom_fea, nbr_fea, nbr_fea_idx), target, cif_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFData('../data/dichalcogenides_public/cifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2966"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deela\\anaconda3\\lib\\site-packages\\pymatgen\\io\\cif.py:1160: UserWarning: Issues encountered while parsing CIF: Some fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: %s\" % \"\\n\".join(self.warnings))\n"
     ]
    }
   ],
   "source": [
    "sample_data = dataset.__getitem__(2965)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(lis):\n",
    "    return [x.shape for x in lis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[192, 92], edge_index=[2, 2304], edge_attr=[2304, 41], y=[1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_graph = dataset.__getitem__(256)\n",
    "fData = Data(x=f_graph[0][0], edge_attr=f_graph[0][1], edge_index=f_graph[0][2], y=f_graph[1])\n",
    "fData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d(dataset, idx):\n",
    "    g = dataset.__getitem__(idx)\n",
    "    d = Data(x=g[0][0], edge_attr=g[0][1], edge_index=g[0][2], y=g[1])\n",
    "    d.__cat_dim__ = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataloaders(data_path, train_size, batch_size):\n",
    "    dataset = CIFData(data_path)\n",
    "    dt_size = len(dataset)\n",
    "    array_idx = np.arange(dt_size)\n",
    "    np.random.shuffle(array_idx)\n",
    "    \n",
    "    train_idxs = array_idx[:train_size]\n",
    "    val_idxs = array_idx[train_size:]\n",
    "\n",
    "    train_dataset = [get_d(dataset, i) for i in train_idxs]\n",
    "    val_dataset = [get_d(dataset, i) for i in val_idxs]\n",
    "    \n",
    "    train_dl = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = gen_dataloaders('../data/dichalcogenides_public/cifs', 2500, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1143, 92], edge_index=[2, 13716], edge_attr=[13716, 41], y=[6], batch=[1143], ptr=[7])\n"
     ]
    }
   ],
   "source": [
    "for data in val_dl:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import GRU, Linear, ReLU, Sequential\n",
    "\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.utils import remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dim = 92\n",
    "dim = 64\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin0 = torch.nn.Linear(inp_dim, dim)\n",
    "\n",
    "        nn = Sequential(Linear(41, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean')\n",
    "        self.gru = GRU(dim, dim)\n",
    "\n",
    "        self.set2set = Set2Set(dim, processing_steps=3)\n",
    "        self.lin1 = torch.nn.Linear(2 * dim, dim)\n",
    "        self.lin2 = torch.nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(3):\n",
    "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "\n",
    "        out = self.set2set(out, data.batch)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=0.7, patience=5,\n",
    "                                                       min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 1\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        error += (model(data) * std - data.y * std).abs().sum().item()  # MAE\n",
    "    return error / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, LR: 0.001000, Loss: 0.2893360, Val MAE: 0.9080289, Test MAE: 0.9080289\n",
      "Epoch: 002, LR: 0.001000, Loss: 0.2600382, Val MAE: 0.8709957, Test MAE: 0.8709957\n",
      "Epoch: 003, LR: 0.001000, Loss: 0.2301515, Val MAE: 0.8276509, Test MAE: 0.8276509\n",
      "Epoch: 004, LR: 0.001000, Loss: 0.1986516, Val MAE: 0.7672089, Test MAE: 0.7672088\n",
      "Epoch: 005, LR: 0.001000, Loss: 0.1610003, Val MAE: 0.6848208, Test MAE: 0.6848208\n",
      "Epoch: 006, LR: 0.001000, Loss: 0.1214515, Val MAE: 0.5998050, Test MAE: 0.5998050\n",
      "Epoch: 007, LR: 0.001000, Loss: 0.0893454, Val MAE: 0.5007034, Test MAE: 0.5007034\n",
      "Epoch: 008, LR: 0.001000, Loss: 0.0858826, Val MAE: 0.4197321, Test MAE: 0.4197321\n",
      "Epoch: 009, LR: 0.001000, Loss: 0.1158958, Val MAE: 0.4123236, Test MAE: 0.4123237\n",
      "Epoch: 010, LR: 0.001000, Loss: 0.1200982, Val MAE: 0.4444587, Test MAE: 0.4123237\n",
      "Epoch: 011, LR: 0.001000, Loss: 0.1035621, Val MAE: 0.4900473, Test MAE: 0.4123237\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12172/3367789976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mval_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12172/3242149720.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0merror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12172/1961769413.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset2set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\glob\\set2set.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, batch)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;34m\"\"\"\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         h = (x.new_zeros((self.num_layers, batch_size, self.in_channels)),\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_error = None\n",
    "for epoch in range(1, 301):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    loss = train(train_dl)\n",
    "    val_error = test(val_dl)\n",
    "    scheduler.step(val_error)\n",
    "\n",
    "    if best_val_error is None or val_error <= best_val_error:\n",
    "        test_error = test(val_dl)\n",
    "        best_val_error = val_error\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, LR: {lr:7f}, Loss: {loss:.7f}, '\n",
    "          f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/QM9'\n",
    "dataset = QM9(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 4], y=[1, 19], pos=[5, 3], idx=[1], name='gdb_1', z=[5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data = dataset[0]\n",
    "f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 11], edge_index=[2, 6], edge_attr=[6, 4], y=[1, 19], pos=[4, 3], idx=[1], name='gdb_2', z=[4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data = dataset[1]\n",
    "s_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aacd9efd2e917f2085b49ad3eecd2bc8a974d0bb8b89bc48afae7fa44e9f517f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
